What if the input is a big file = 1T?Can we process it with one machine?
No!
--Out of memory
--Too slow
What should we do?
Use multiple machines
Issues may be caused by multiple machines：
  -Data Skew 数据倾斜
  -Node Failure
Then MapReduce Comes Out
MapReduce:
A programming model for processing and generating large data sets with a parallel, distributed algorithm on a cluster.

How to Solve Data Skew Problem:
数据倾斜是一个在MapReduce中可能会出现的问题，共有以下几种解决方案
1、增加jvm内存,这适用于第一种情况(唯一值非常少，极少数值有非常多的记录值(唯一值少于几千)),这种情况下,往往只能通过硬件的手段来进行调优,增加jvm内存可以显著的提高运行效率
2、增加reduce的个数,这适用于第二种情况(唯一值比较多，这个字段的某些值有远远多于其他值的记录数，但是它的占比也小于百分之一或千分之一),我们知道,这种情况下,最容易造成的结果就是大量相同key被partition到一个分区,从而一个reduce执行了大量的工作,而如果我们增加了reduce的个数,这种情况相对来说会减轻很多,毕竟计算的节点多了,就算工作量还是不均匀的,那也要小很多。
3、自定义分区,这需要用户自己继承partition类,指定分区策略,这种方式效果比较显著。
4、重新设计key,有一种方案是在map阶段时给key加上一个随机数,有了随机数的key就不会被大量的分配到同一节点(小几率),待到reduce后再把随机数去掉即可。
5、使用combinner合并,combinner是在map阶段,reduce之前的一个中间阶段,在这个阶段可以选择性的把大量的相同key数据先进行一个合并,可以看做是local reduce,然后再交给reduce来处理,这样做的好处很多,即减轻了map端向reduce端发送的数据量(减轻了网络带宽),也减轻了map端和reduce端中间的shuffle阶段的数据拉取数量(本地化磁盘IO速率),推荐使用这种方法。
workflow inside MapReduce:
1.Mapper:
  A stage
  ○ Splits into small words
  Implementation
  ○ https://hadoop.apache.org/docs/r2.6.2/api/org/apache/hadoop/mapreduce/Mapper.html
  ○ Simplify your work
2.Reducer: 
  A stage
  ○ Combines data from Mapper
  Implementation
  ○ https://hadoop.apache.org/docs/r2.6.2/api/org/apache/hadoop/mapreduce/Reducer.html
  ○ Simplify your work
 Hadoop的优点：
 1.Throughput
  ○ Run computation in parallel
 2.Scalability
  ○ Store and distribute very large data sets across clusters of hundreds of
  inexpensive servers operating in parallel
  3.Reliability
  ○ Even if individual nodes experience high rates of failure when running jobs on a
  large cluster, data is replicated across a cluster so that it can be recovered easily
  in the face of disk, node or rack failures
  4.Cheap
  ○ Cluster of inexpensive servers
    
